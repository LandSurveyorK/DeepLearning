{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "TensorFlow Version:1.7.0\n",
      "Eager excution: True\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.VERSION)\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "print(\"TensorFlow Version:{}\".format(tf.VERSION))\n",
    "print(\"Eager excution: {}\".format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version:1.7.0\n",
      "Eager excution: False\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local copy of the dataset file:C:\\Users\\WEI\\.keras\\datasets\\iris_training.csv\n"
     ]
    }
   ],
   "source": [
    "train_dataset_url = 'http://download.tensorflow.org/data/iris_training.csv'\n",
    "train_dataset_fp = tf.keras.utils.get_file(fname=os.path.basename(train_dataset_url),\n",
    "                                          origin=train_dataset_url)\n",
    "print(\"Local copy of the dataset file:{}\".format(train_dataset_fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example features: tf.Tensor([7.2 3.  5.8 1.6], shape=(4,), dtype=float32)\n",
      "example label: tf.Tensor(2.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def parse_csv(line):\n",
    "    \n",
    "    example_defaults = [[0.],[0.],[0.],[0.],[0.]]\n",
    "    parsed_line = tf.decode_csv(line,example_defaults)\n",
    "    features = tf.reshape(parsed_line[:-1], shape=(4,))\n",
    "    label = tf.reshape(parsed_line[-1], shape=())\n",
    "    \n",
    "    return features, label\n",
    "\n",
    "train_dataset = tf.data.TextLineDataset(train_dataset_fp)\n",
    "train_dataset = train_dataset.skip(1)             # skip the first header row\n",
    "train_dataset = train_dataset.map(parse_csv)      # parse each row\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1000)  # randomize\n",
    "train_dataset = train_dataset.batch(32)\n",
    "\n",
    "# View a single example entry from a batch\n",
    "features, label = tfe.Iterator(train_dataset).next()\n",
    "print(\"example features:\", features[0])\n",
    "print(\"example label:\", label[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Value for attr 'Tlabels' of float is not in the list of allowed values: int32, int64\n\t; NodeDef: SparseSoftmaxCrossEntropyWithLogits = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_FLOAT](dummy_input, dummy_input); Op<name=SparseSoftmaxCrossEntropyWithLogits; signature=features:T, labels:Tlabels -> loss:T, backprop:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=Tlabels:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]> [Op:SparseSoftmaxCrossEntropyWithLogits] name: xentropy",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-9b240ec3bbeb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m# Optimize the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         optimizer.apply_gradients(zip(grads, model.variables),\n\u001b[0;32m     35\u001b[0m                               global_step=tf.train.get_or_create_global_step())\n",
      "\u001b[1;32m<ipython-input-12-9b240ec3bbeb>\u001b[0m in \u001b[0;36mgrad\u001b[1;34m(model, inputs, targets)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-9b240ec3bbeb>\u001b[0m in \u001b[0;36mloss\u001b[1;34m(model, x, y)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0my_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_softmax_cross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy\u001b[1;34m(labels, logits, weights, scope, loss_collection, reduction)\u001b[0m\n\u001b[0;32m    846\u001b[0m     losses = nn.sparse_softmax_cross_entropy_with_logits(labels=labels,\n\u001b[0;32m    847\u001b[0m                                                          \u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m                                                          name=\"xentropy\")\n\u001b[0m\u001b[0;32m    849\u001b[0m     return compute_weighted_loss(\n\u001b[0;32m    850\u001b[0m         losses, weights, scope, loss_collection, reduction=reduction)\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[1;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[0;32m   2050\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2051\u001b[0m       cost, _ = gen_nn_ops.sparse_softmax_cross_entropy_with_logits(\n\u001b[1;32m-> 2052\u001b[1;33m           precise_logits, labels, name=name)\n\u001b[0m\u001b[0;32m   2053\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2054\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[1;34m(features, labels, name)\u001b[0m\n\u001b[0;32m   8012\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8013\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 8014\u001b[1;33m       \u001b[0m_six\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8016\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Value for attr 'Tlabels' of float is not in the list of allowed values: int32, int64\n\t; NodeDef: SparseSoftmaxCrossEntropyWithLogits = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_FLOAT](dummy_input, dummy_input); Op<name=SparseSoftmaxCrossEntropyWithLogits; signature=features:T, labels:Tlabels -> loss:T, backprop:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=Tlabels:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]> [Op:SparseSoftmaxCrossEntropyWithLogits] name: xentropy"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='relu', input_shape=(4,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3)\n",
    "])\n",
    "\n",
    "def loss(model, x, y):\n",
    "    y_ = model(x)\n",
    "    return tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)\n",
    "\n",
    "def grad(model, inputs, targets):\n",
    "    with tfe.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets)\n",
    "    return tape.gradient(loss_value, model.variables)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "\n",
    "## Note: Rerunning this cell uses the same model variables\n",
    "\n",
    "# keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 201\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_avg = tfe.metrics.Mean()\n",
    "    epoch_accuracy = tfe.metrics.Accuracy()\n",
    "\n",
    "  # Training loop - using batches of 32\n",
    "    for x, y in tfe.Iterator(train_dataset):\n",
    "    # Optimize the model\n",
    "        grads = grad(model, x, y)\n",
    "        optimizer.apply_gradients(zip(grads, model.variables),\n",
    "                              global_step=tf.train.get_or_create_global_step())\n",
    "\n",
    "    # Track progress\n",
    "        epoch_loss_avg(loss(model, x, y))  # add current batch loss\n",
    "    # compare predicted label to actual label\n",
    "        epoch_accuracy(tf.argmax(model(x), axis=1, output_type=tf.int32), y)\n",
    "\n",
    "  # end epoch\n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_accuracy_results.append(epoch_accuracy.result())\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
    "                                                                epoch_loss_avg.result(),\n",
    "                                                                epoch_accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAucAAAIdCAYAAACeDtO3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
    "fig.suptitle('Training Metrics')\n",
    "\n",
    "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
    "axes[0].plot(train_loss_results)\n",
    "\n",
    "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
    "axes[1].plot(train_accuracy_results)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
